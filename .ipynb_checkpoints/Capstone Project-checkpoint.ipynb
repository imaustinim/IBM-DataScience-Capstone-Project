{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: conda: command not found\n",
      "/bin/sh: conda: command not found\n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://en.wikipedia.org/wiki/List_of_cities_by_international_visitors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a handle, page, to handle the contents of the website\n",
    "page = requests.get(url)\n",
    "#Store the contents of the website under doc\n",
    "doc = lh.fromstring(page.content)\n",
    "#Parse data that are stored between <tr>..</tr> of HTML\n",
    "tr_elements = doc.xpath('//tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the length of the first 12 rows\n",
    "[len(T) for T in tr_elements[:12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:RankEuromonitor\n",
      "\n",
      "2:RankMastercard\n",
      "\n",
      "3:City\n",
      "\n",
      "4:Country\n",
      "\n",
      "5:Arrivals 2017Euromonitor\n",
      "\n",
      "6:Arrivals 2016Mastercard\n",
      "\n",
      "7:Growthin arrivalsEuromonitor\n",
      "\n",
      "8:Income(billions $)Mastercard\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create empty list\n",
    "col=[]\n",
    "i=0\n",
    "#For each row, store each first element (header) and an empty list\n",
    "for t in tr_elements[0]:\n",
    "    i+=1\n",
    "    name=t.text_content()\n",
    "    print('%d:%s'%(i,name))\n",
    "    col.append((name,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since out first row is the header, data is stored on the second row onwards\n",
    "for j in range(1,len(tr_elements)):\n",
    "    #T is our j'th row\n",
    "    T=tr_elements[j]\n",
    "    \n",
    "    #If row is not of size 10, the //tr data is not from our table \n",
    "    if len(T)!=8:\n",
    "        break\n",
    "    \n",
    "    #i is the index of our column\n",
    "    i=0\n",
    "    \n",
    "    #Iterate through each element of the row\n",
    "    for t in T.iterchildren():\n",
    "        data=t.text_content() \n",
    "        #Check if row is empty\n",
    "        if i>0:\n",
    "        #Convert any numerical value to integers\n",
    "            try:\n",
    "                data=int(data)\n",
    "            except:\n",
    "                pass\n",
    "        #Append the data to the empty list of the i'th column\n",
    "        col[i][1].append(data)\n",
    "        #Increment i for the next column\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[274, 274, 274, 274, 274, 274, 274, 274]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the length of each column\n",
    "[len(C) for (title,C) in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dictionary and DataFrame\n",
    "Dict={title:column for (title,column) in col}\n",
    "df_raw=pd.DataFrame(Dict)\n",
    "df_raw.head()\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean up the DataFrame\n",
    "df = df_raw\n",
    "df.rename(columns={'RankEuromonitor\\n':'RankMastercard','City\\n':'City','Country\\n':'Country','Arrivals 2017Euromonitor\\n':'Arrivals','Growthin arrivalsEuromonitor\\n':'Growth'}, inplace=True)\n",
    "df = df.replace('\\n','', regex=True) #get rid of all \\n in the DataFrame\n",
    "df = df.replace('\\xa0','', regex=True) #get rid of all \\n in the DataFrame\n",
    "df = df.replace('',np.nan, regex=True) #replace \"Not Assigned\" values to NaN\n",
    "df.drop(['RankMastercard\\n','Arrivals 2016Mastercard\\n','Income(billions $)Mastercard\\n'], axis=1,inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City, Country'] = df['City'] + ', ' + df['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hong Kong, Hong Kong', 'Bangkok, Thailand',\n",
       "       'London, United Kingdom', 'Singapore, Singapore', 'Macau, Macau',\n",
       "       'Dubai, United Arab Emirates', 'Paris, France',\n",
       "       'New York City, United States', 'Shenzhen, China',\n",
       "       'Kuala Lumpur, Malaysia', 'Phuket, Thailand', 'Delhi, India',\n",
       "       'Tokyo, Japan', 'Rome, Italy', 'Taipei, Taiwan',\n",
       "       'Guangzhou, China', 'Mumbai, India', 'Mecca, Saudi Arabia',\n",
       "       'Istanbul, Turkey', 'Prague, Czech Republic',\n",
       "       'Miami, United States', 'Seoul, South Korea', 'Barcelona, Spain',\n",
       "       'Pattaya, Thailand', 'Shanghai, China', 'Milan, Italy',\n",
       "       'Canc√∫n, Mexico', 'Agra, India', 'Las Vegas, United States',\n",
       "       'Amsterdam, Netherlands', 'Antalya, Turkey', 'Denpasar, Indonesia',\n",
       "       'Osaka, Japan', 'Los Angeles, United States', 'Vienna, Austria',\n",
       "       'Berlin, Germany', 'Madrid, Spain', 'Johor Bahru, Malaysia',\n",
       "       'Johannesburg, South Africa', 'Riyadh, Saudi Arabia',\n",
       "       'Ho Chi Minh City, Vietnam', 'Venice, Italy',\n",
       "       'Orlando, United States', 'Chennai, India', 'Jaipur, India',\n",
       "       'Athens, Greece', 'Dublin, Ireland', 'Florence, Italy',\n",
       "       'Moscow, Russia', 'Toronto, Canada'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top = df['City, Country'][:50].values\n",
    "df_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
